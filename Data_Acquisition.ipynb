{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will walk you through acquiring the related TNG-100 data before further analysis can be done. \n",
    "\n",
    "First, import the necessary functions. Make sure to provide the right local path to the custom module ```simulation_data```. This module is required for generating the figures from the paper.\n",
    "\n",
    "**Downloading data requires an API key from the IllustrisTNG server.** If this your first time working with TNG data, visit https://www.tng-project.org/data/docs/api/ and click on _New User Registration_ to create a user account and request an API key. \n",
    "\n",
    "#### Once in possession of your **API key**, navigate to ```simulation_data.__init__``` and set the variable ```API = \"???\"``` with your API key as a string.\n",
    "\n",
    "### Import custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation_data import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from simulation_data.galaxies import GalaxyPopulation\n",
    "my_galaxy_population = GalaxyPopulation()\n",
    "from simulation_data.galaxies.galaxy import get_galaxy_particle_data, get_stellar_assembly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download particle data\n",
    "Now, download targeted particle data for galaxies only within the specified mass cut at the specified redshift. This cell downloads particle data for all $z=2$ galaxies within $10^{10.5} \\leq M_{*}/M_{\\odot} \\leq 10^{12}$. \n",
    "\n",
    "Remember to check the path specified in the function ```get_galaxy_particle_data``` in ```simulation_data.galaxies.galaxy``` and make sure it points to a valid local drive. Within the target drive, create a folder titled ```'redshift_'+str(redshift)+'_data``` before running this cell. Note that the ```get_stellar_assembly_data``` needs a pre-existing stellar assembly file to run. Generating Figures 4 and 5 in the ```Figures``` notebook partially depends on the stellar assembly files for $z=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = 2\n",
    "#this initializes the values in simulation_data.galaxies.galaxy_population\n",
    "ids = my_galaxy_population.select_galaxies(redshift=redshift, mass_min=10.5, mass_max=12)\n",
    "\n",
    "#this gets and saves the particle data for each galaxy in our selection\n",
    "for idx in ids:\n",
    "    get_galaxy_particle_data(id=idx, redshift=redshift, populate_dict=False)\n",
    "    #Download Stellar Assembly Files for the chosen redshift before attempting to get particle assembly data\n",
    "    get_stellar_assembly_data(id=idx, redshift=redshift, populate_dict==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Main Progenitor and Descendent ids\n",
    "\n",
    "We now get the ids for the progenitors and descendents of our population identified at $z=2$. This example finds the main progenitor for each galaxy at $z=3$ and the descendant at $z=1.5$. It saves the arrays of ids at each redshift in the file ```redshift_ids.hdf5```. This step may be time-consuming. The intermediate print statements are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2_ids = ids\n",
    "z3_ids = np.array([-1]*(len(ids)))\n",
    "z1_5_ids = np.array([-1]*(len(ids)))\n",
    "\n",
    "\n",
    "#Finding the progenitors at z=3   \n",
    "count = 0\n",
    "print('z=3', z3_ids)\n",
    "for i, id in enumerate(z2_ids):\n",
    "    if z3_ids[i] == -1:\n",
    "        start_url = \"http://www.tng-project.org/api/TNG100-1/snapshots/33/subhalos/\" + str(id)\n",
    "        sub = get(start_url)  \n",
    "        while sub['prog_sfid'] != -1:\n",
    "            # request the full subhalo details of the progenitor by following the sublink URL\n",
    "            sub = get(sub['related']['sublink_progenitor'])\n",
    "            if sub['snap'] == 25:\n",
    "                z3_ids[i] = sub['id'] \n",
    "    count += 1\n",
    "    print(count)\n",
    "with h5py.File('redshift_ids.hdf5', 'a') as f:\n",
    "    d1 = f.create_dataset('z3_ids', data = z3_ids)\n",
    "    d2 = f.create_dataset('z2_ids', data = z2_ids)\n",
    "    \n",
    "#Finding the descendants at z=1.5\n",
    "count = 0\n",
    "print('z=1.5', z1_5_ids)\n",
    "for i, id in enumerate(z2_ids):\n",
    "    if z1_5_ids[i] == -1:\n",
    "        start_url = \"http://www.tng-project.org/api/TNG100-1/snapshots/33/subhalos/\" + str(id)\n",
    "        sub = get(start_url)   \n",
    "        while sub['desc_sfid'] != -1:\n",
    "            # request the full subhalo details of the progenitor by following the sublink URL\n",
    "            sub = get(sub['related']['sublink_descendant'])\n",
    "            if sub['snap'] == 40:\n",
    "                z1_5_ids[i] = sub['id']         \n",
    "    count += 1\n",
    "    print(count)\n",
    "with h5py.File('redshift_ids.hdf5', 'a') as f:\n",
    "    d3 = f.create_dataset('z1.5_ids', data = z1_5_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download particle for linked ids at different redshifts\n",
    "\n",
    "For each new set of ids for progenitors and descendants, now repeat the steps from the second cell to get and save the particle data for each galaxy at the new redshift. \n",
    "\n",
    "Remember to create new folders for each redshift you look at. We do not add the stellar assembly data for these redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('redshift_ids.hdf5', 'r') as f:\n",
    "    z1_5_ids = f['z1.5_ids'][:]\n",
    "    z3_ids = f['z3_ids'][:]\n",
    "\n",
    "redshift = 1.5\n",
    "for idx in z1_5_ids:\n",
    "    get_galaxy_particle_data(id=idx, redshift=redshift, populate_dict=False)\n",
    "    \n",
    "redshift = 3\n",
    "for idx in z1_5_ids:\n",
    "    get_galaxy_particle_data(id=idx, redshift=redshift, populate_dict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our section on downloading data. \n",
    "\n",
    "### Calculate halo properties from particle data\n",
    "\n",
    "To speed up analysis, we now calculate and store some halo properties in a separate hdf5 file named ```'galaxy_population_data_'+str(self.redshift)+'.hdf5'```. Remember to finish running the above section before moving on to the steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = 2\n",
    "#this initializes the values in simulation_data.galaxies.galaxy_population\n",
    "ids = my_galaxy_population.select_galaxies(redshift=redshift, mass_min=10.5, mass_max=12)\n",
    "\n",
    "#calculate halo properties and store calculated data\n",
    "my_galaxy_population.get_galaxy_population_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some shortcuts\n",
    "\n",
    "Walking down merger trees can be time consuming. Stellar assembly files may be hard to come by/compile from scratch. So here are some shortcuts. \n",
    "\n",
    "### Select post-processed data included\n",
    "Post-processed data from TNG-100 that has been used to generate the figures in this paper are included in ```galaxy_population_data_2.hdf5``` and ```redshift_ids.hdf5```. Each array stores a halo property each halo at $z=2$, arranged by the order of ids in ```'ids'```. These properties can also be easily recalculated from raw TNG-100 data and stored in the same format by following the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
